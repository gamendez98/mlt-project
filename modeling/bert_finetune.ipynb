{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2760f8e-837a-4d1a-8dee-a89e1c13c3f6",
   "metadata": {},
   "source": [
    "# Fine-tuning BETO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad8f3ae-4ebe-4810-8378-130f3f77c4df",
   "metadata": {},
   "source": [
    "Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cbbbef-6ae4-4d0b-b19f-f323bbcf935e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiante/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-24 16:53:16.259792: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-24 16:53:16.309757: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-24 16:53:17.225038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, DataCollatorForTokenClassification, Trainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings, evaluate, pickle, json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datasets import disable_caching\n",
    "disable_caching()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f7cf0-4952-493f-8eff-c01c802c61c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b7948a-dbd1-4764-9e02-11928b9019b3",
   "metadata": {},
   "source": [
    "We load the dataset using the `datasets` library function `load_dataset`. This is the format used by Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753442ce-980d-4297-8fc8-bf0a66b31423",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"json\", data_files={\"train\": \"data/train_data.json\", \"validation\": \"data/val_data.json\", \"test\": \"data/test_data.json\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a0469a-b4d8-4652-8ad6-dc97aae00b39",
   "metadata": {},
   "source": [
    "Using the model id we can load both model and tokenizer. Since we have a special token `@PADDING`, we shall add it to the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab484f81-11b6-4c1b-9d28-dd6d0a434cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_tokens(new_tokens = [\"@@PADDING@@\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55babaa0-7a81-46f4-8f5e-3e69fbd4dbe0",
   "metadata": {},
   "source": [
    "Let us quickly check how the tokenizer transform our words. Two things stand out:\n",
    "\n",
    "- It adds special tokens to the beginning and end of the sentence, `[CLS]` and `[SEP]`. We will have to let the model know that these are special tokens.\n",
    "- It breaks some words, indicating this by two hashes at the beginning of the token, for example, ##subword. When rearranging labels, we'll have to be sure to label only the first word of the decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2487746e-a048-43a0-a676-15a1fc877099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '@@PADDING@@',\n",
       " 'Aun',\n",
       " 'así',\n",
       " 'no',\n",
       " 'hemos',\n",
       " 'mi',\n",
       " 'favorito',\n",
       " 'de',\n",
       " 'los',\n",
       " 'poca',\n",
       " 'que',\n",
       " 'AN',\n",
       " '##TE',\n",
       " 'el',\n",
       " 'momento',\n",
       " 'SER',\n",
       " '##Á',\n",
       " '##N',\n",
       " 'podido',\n",
       " 'escuchar',\n",
       " 'de',\n",
       " 'Pe',\n",
       " '##er',\n",
       " '##G',\n",
       " '##yn',\n",
       " '##t',\n",
       " 'Lobo',\n",
       " '##gri',\n",
       " '##s',\n",
       " 'fuimos',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "tokenized_input = tokenizer(example[\"modified_words\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7c311-e90f-44b0-9e17-a1e955aace64",
   "metadata": {},
   "source": [
    "The next function tokenizes our phrase, and reassign its labels accordingly. Particularly, it will label as -100 both [CLS] and [SEP], and it will only label the first word of a decomposition, telling the model to ignore the rest with the label -100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678cfb6c-eb2b-4f29-81ac-f8a9c62aa898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"modified_words\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fecfb2-99ec-4eb8-8669-9b7fbce60351",
   "metadata": {},
   "source": [
    "We map our dataset with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d49de8-8b2d-4112-b1af-2f6a4ba58b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████| 819832/819832 [01:06<00:00, 12329.88 examples/s]\n",
      "Map: 100%|████████████████████| 234237/234237 [00:19<00:00, 12140.06 examples/s]\n",
      "Map: 100%|████████████████████| 117120/117120 [00:09<00:00, 12267.51 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4de33-6ca5-4357-b8cf-09ef78730986",
   "metadata": {},
   "source": [
    "With it, we can define the `data_collator` for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec86a6b5-d3ed-4895-8426-e009c887e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95de349-f6af-4251-87b2-887d85e3d710",
   "metadata": {},
   "source": [
    "With our previously saved `LabelEncoder` we will define dictionaries `id2label` and `label2id` to jump between our integer representations and our labels. This info will also be passed out to the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f90912-1b65-4093-97f4-65568b5e8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/labelencoder.pkl\",\"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "\n",
    "id2label = {i: le.classes_[i] for i in range(len(le.classes_))}\n",
    "label2id = {id2label[j]: j for j in range(len(id2label))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645f201-38df-44ab-8535-48fa3f8e9c68",
   "metadata": {},
   "source": [
    "We load the model, also rezising it accordingly to the tokenizer, since we added one more token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982f3953-4384-4cf9-9f74-6594a1702b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(31003, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_id, num_labels=len(le.classes_), id2label=id2label, label2id=label2id)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e5c1f-0de2-4024-a6fe-f3d8c64c8e02",
   "metadata": {},
   "source": [
    "We will be computing metrics with the help of the `seqeval` library. We also define a function to preprocess the logits for the metrics calculation, this will help out optimizing the training and evaluation loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a4b6cb-30a6-4f37-b56a-19306febf338",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    \n",
    "    predictions = p.predictions\n",
    "    labels = p.label_ids\n",
    "    \n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_ids = np.argmax(logits.cpu(), axis=2)\n",
    "    return pred_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285dd829-8212-4e8c-83a0-ffcc70936a2b",
   "metadata": {},
   "source": [
    "Now, the `TrainingArguments` definition. We shall train for 3 epochs, with a precision of `fp16`. We'll only save the best model based on the `f1-score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a5b87b-6dae-45e2-83d3-5275b80e2c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76860' max='76860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76860/76860 4:11:29, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>0.210232</td>\n",
       "      <td>0.875939</td>\n",
       "      <td>0.832718</td>\n",
       "      <td>0.853782</td>\n",
       "      <td>0.946279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.183330</td>\n",
       "      <td>0.886929</td>\n",
       "      <td>0.855005</td>\n",
       "      <td>0.870674</td>\n",
       "      <td>0.952287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.181506</td>\n",
       "      <td>0.888872</td>\n",
       "      <td>0.863606</td>\n",
       "      <td>0.876057</td>\n",
       "      <td>0.954033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=76860, training_loss=0.22168434643354573, metrics={'train_runtime': 15090.5712, 'train_samples_per_second': 162.982, 'train_steps_per_second': 5.093, 'total_flos': 1.21867179207792e+17, 'train_loss': 0.22168434643354573, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_model_bert\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    save_total_limit=1,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d4e9f-e2cf-482a-b90f-b7a23528f64c",
   "metadata": {},
   "source": [
    "Then, we'll save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf77196-2f53-48aa-acb9-67d1ea3d571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"bert_ner_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
