{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72deccc5-8d01-4312-b6aa-367d25fef195",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5953385e-74d0-4b0a-b584-fa59dab08360",
   "metadata": {},
   "source": [
    "Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b78d99-b71c-4cdf-aa0e-de8b71949ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/estudiante/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-05-24 22:06:51.389575: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-24 22:06:51.440437: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-24 22:06:52.353690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, DataCollatorForTokenClassification, Trainer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings, evaluate, pickle, json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20665ccd-e317-4360-800e-f18fe27a2db4",
   "metadata": {},
   "source": [
    "Change the DATA_DIR with your own folder where data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c23e7f-e09b-451b-a486-7c6cb159da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d546b6c-2b9c-49d4-a249-5723da0a2405",
   "metadata": {},
   "source": [
    "The testing pipeline is the same for both models:\n",
    "\n",
    "1. Load model and tokenizer from locally saved fine-tuned model.\n",
    "2. Load only the test dataset. Define the same function from the training pipeline to tokenize and align the labels accordingly.\n",
    "3. Map the function to the test dataset and define the data collator.\n",
    "4. Load the label encoder and create mappings between labels and IDs. This is to compute metrics.\n",
    "5. Load the seqeval library for evaluation and define the function to compute evaluation metrics, and the function to preprocess logits for metrics.\n",
    "6. Define a Trainer instance in order to easy evaluation. Into the training arguments, it is important to set do_train in False, so the weights will not be updated.\n",
    "7. Evaluate the test dataset and print results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784186dd-bea1-47ab-a5b7-2c846a37da83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BERT on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b505fb6b-cae8-449a-9356-769fa536617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert_ner_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09817299-fbc0-4017-8b9b-9b7bff0074ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"json\", data_files={\"test\": f\"{DATA_DIR}/test_data.json\"})[\"test\"]\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"modified_words\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7897e96d-f830-4dfe-8904-a036605747e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████| 117120/117120 [00:09<00:00, 11926.88 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d00fc5-75aa-449d-8d3c-dfb603aa3924",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/labelencoder.pkl\",\"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "id2label = {i: le.classes_[i] for i in range(len(le.classes_))}\n",
    "label2id = {id2label[j]: j for j in range(len(id2label))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1283c30c-b3d9-4582-8fa6-1f65b896b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions = p.predictions\n",
    "    labels = p.label_ids\n",
    "    \n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_ids = np.argmax(logits.cpu(), axis=2)\n",
    "    return pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9f7ea4-f5dd-4601-a3b2-b677e98c025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 07:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18253612518310547, 'eval_precision': 0.8892020121861458, 'eval_recall': 0.8640431102871964, 'eval_f1': 0.8764420473037796, 'eval_accuracy': 0.9542758773490764, 'eval_runtime': 557.8663, 'eval_samples_per_second': 209.943, 'eval_steps_per_second': 6.561}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate(eval_dataset=tokenized_dataset)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c85db-639f-4150-8712-bb0ce836023e",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8aff82-5b8d-49cf-a338-d987fd9f33cd",
   "metadata": {},
   "source": [
    "## RoBERTa on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1307a251-8c77-447c-a806-9c65083b4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"roberta_ner_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b316d5d9-2502-4475-971d-e44cf6c1c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_dataset(\"json\", data_files={\"test\": f\"{DATA_DIR}/test_data.json\"})[\"test\"]\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"modified_words\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c95f9d6-e28c-480d-b372-320590216faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████| 117120/117120 [00:09<00:00, 12681.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4de8e28-0b7b-4a20-a132-875da621c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/labelencoder.pkl\",\"rb\") as f:\n",
    "    le = pickle.load(f)\n",
    "id2label = {i: le.classes_[i] for i in range(len(le.classes_))}\n",
    "label2id = {id2label[j]: j for j in range(len(id2label))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a854b42c-7652-4449-ad15-843498813843",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions = p.predictions\n",
    "    labels = p.label_ids\n",
    "    \n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    pred_ids = np.argmax(logits.cpu(), axis=2)\n",
    "    return pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32b4b34-ae51-4497-be67-7b1889a8c3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3660' max='3660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3660/3660 12:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17509829998016357, 'eval_precision': 0.8947445331927776, 'eval_recall': 0.870805817412943, 'eval_f1': 0.8826128853650539, 'eval_accuracy': 0.9565493488181205, 'eval_runtime': 849.9891, 'eval_samples_per_second': 137.79, 'eval_steps_per_second': 4.306}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    do_train=False,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")\n",
    "\n",
    "eval_result = trainer.evaluate(eval_dataset=tokenized_dataset)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abd3568-8c4c-4789-bc7c-ed8bc5a32e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
