{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DEMO\n",
    "\n",
    "\n",
    "The following notebook is a demonstration on how to use the tools in this repository to create\n",
    "Initial data\n"
   ],
   "id": "441ea3263056bf87"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:30:55.110153Z",
     "start_time": "2024-05-26T18:30:55.107435Z"
    }
   },
   "source": [
    "import datasets\n",
    "from data_preparation.synthetic_dataset_creation import create_or_load_inflector, create_or_load_stop_word_dictionary\n",
    "from data_preparation.sentence_modifier import SentenceModifier\n",
    "import spacy\n",
    "from grammar_error_correction.grammar_error_correction import KEEP\n",
    "import pandas as pd\n",
    "from grammar_error_correction.grammar_error_correction import GrammarErrorCorrector\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset structure\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"original_words\": [\"@@PADDING@@\", \"El\", \"ama\", \"los\", \"gatos\", \".\"],\n",
    "    \"modified_words\": [\"@@PADDING@@\", \"El\", \"ama\", \"gatos\", \".\"],\n",
    "    \"labels\": [\"$KEEP\", \"$KEEP\", \"$APPEND_los\", \"$KEEP\", \"$KEEP\"]\n",
    "  },\n",
    "  \n",
    "  {}\n",
    "  \n",
    "]\n",
    "```"
   ],
   "id": "6711a6a16055ca80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LABELS\n",
    "\n",
    "- KEEP: No change is needed in this position\n",
    "- DELETE`: The word corresponding to this position has to be removed\n",
    "- APPEND_<word>: append the token `<word>` after the position of this label \n",
    "- SPLIT_<place>: split the word at this position at the character `<place>`\n",
    "- REPLACE_<word>: replace the word at this position for `<word>`"
   ],
   "id": "3fdc0c2f50c243e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For the creation of our dataset we need a base dataset of correct sentences. In our case we picked https://huggingface.co/datasets/crscardellino/spanish_billion_words. For this small demo we are going to need just a few examples. About 10 will do",
   "id": "6e43a8dd6f5b8f44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:31:09.055490Z",
     "start_time": "2024-05-26T18:31:04.881153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_dataset_path = 'spanish_billion_words'\n",
    "sample_size = 10\n",
    "texts = datasets.load_dataset(raw_dataset_path, trust_remote_code=True)['train'][:10]['text']\n",
    "print(texts)"
   ],
   "id": "bcc90b8b924744e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46988ecefa1a45d589900f73866ace14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Source Wikisource librodot com SENTIDO Y SENSIBILIDAD JANE AUSTEN CAPITULO I', 'La familia Dashwood llevaba largo tiempo afincada en Sussex', 'Su propiedad era de buen tamaño y en el centro de ella se encontraba la residencia Norland Park donde la manera tan digna en que habían vivido por muchas generaciones llegó a granjearles el respeto de todos los conocidos del lugar', 'El último dueño de esta propiedad había sido un hombre soltero que alcanzó una muy avanzada edad y que durante gran parte de su existencia tuvo en su hermana una fiel compañera y ama de casa', 'Pero la muerte de ella ocurrida diez años antes que la suya produjo grandes alteraciones en su hogar', 'Para compensar tal pérdida invitó y recibió en su casa a la familia de su sobrino el señor Henry Dashwood el legítimo heredero de la finca Norland y la persona a quien se proponía dejarla en su testamento', 'En compañía de su sobrino y sobrina y de los hijos de ambos la vida transcurrió confortablemente para el anciano caballero', 'Su apego a todos ellos fue creciendo con el tiempo', 'La constante atención que el señor Henry Dashwood y su esposa prestaban a sus deseos nacida no del mero interés sino de la bondad de sus corazones hizo su vida confortable en todo aquello que por su edad podía convenirle y la alegría de los niños añadía nuevos deleites a su existencia', 'De un matrimonio anterior el señor Henry Dashwood tenía un hijo y de su esposa actual tres hijas']\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:31:18.438734Z",
     "start_time": "2024-05-26T18:31:18.433793Z"
    }
   },
   "cell_type": "code",
   "source": "texts",
   "id": "5b8e91b1f8aaa201",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Source Wikisource librodot com SENTIDO Y SENSIBILIDAD JANE AUSTEN CAPITULO I',\n",
       " 'La familia Dashwood llevaba largo tiempo afincada en Sussex',\n",
       " 'Su propiedad era de buen tamaño y en el centro de ella se encontraba la residencia Norland Park donde la manera tan digna en que habían vivido por muchas generaciones llegó a granjearles el respeto de todos los conocidos del lugar',\n",
       " 'El último dueño de esta propiedad había sido un hombre soltero que alcanzó una muy avanzada edad y que durante gran parte de su existencia tuvo en su hermana una fiel compañera y ama de casa',\n",
       " 'Pero la muerte de ella ocurrida diez años antes que la suya produjo grandes alteraciones en su hogar',\n",
       " 'Para compensar tal pérdida invitó y recibió en su casa a la familia de su sobrino el señor Henry Dashwood el legítimo heredero de la finca Norland y la persona a quien se proponía dejarla en su testamento',\n",
       " 'En compañía de su sobrino y sobrina y de los hijos de ambos la vida transcurrió confortablemente para el anciano caballero',\n",
       " 'Su apego a todos ellos fue creciendo con el tiempo',\n",
       " 'La constante atención que el señor Henry Dashwood y su esposa prestaban a sus deseos nacida no del mero interés sino de la bondad de sus corazones hizo su vida confortable en todo aquello que por su edad podía convenirle y la alegría de los niños añadía nuevos deleites a su existencia',\n",
       " 'De un matrimonio anterior el señor Henry Dashwood tenía un hijo y de su esposa actual tres hijas']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Text transformations\n",
    "\n",
    "Now that we haver our texts samples we can start creating our dataset. This will require us to create an `Inflector` and a `StopWordDictionary`"
   ],
   "id": "c3574f2341fa0a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:31:57.591742Z",
     "start_time": "2024-05-26T18:31:57.255003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inflector_path = 'data/inflector.json'\n",
    "stop_word_dictionary_path = 'data/stop_word_dictionary.json'\n",
    "nlp_model = spacy.load('es_core_news_sm')\n",
    "\n",
    "inflector = create_or_load_inflector(inflector_path, raw_dataset_path, nlp_model, sample_size)\n",
    "stop_word_dictionary = create_or_load_stop_word_dictionary(stop_word_dictionary_path, raw_dataset_path, nlp_model,\n",
    "                                                           sample_size)"
   ],
   "id": "68bf9491ff05bad7",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:32:21.081499Z",
     "start_time": "2024-05-26T18:32:21.078658Z"
    }
   },
   "cell_type": "code",
   "source": "inflector.inflections['NOUN']['conocido']",
   "id": "d9d11431f871d17d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conocido', 'conocidos']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:32:37.003547Z",
     "start_time": "2024-05-26T18:32:37.000576Z"
    }
   },
   "cell_type": "code",
   "source": "stop_word_dictionary.stop_words_by_pos['DET']",
   "id": "c4111b95c9148a70",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['suya',\n",
       " 'esta',\n",
       " 'la',\n",
       " 'La',\n",
       " 'El',\n",
       " 'todo',\n",
       " 'una',\n",
       " 'un',\n",
       " 'los',\n",
       " 'Su',\n",
       " 'el',\n",
       " 'sus',\n",
       " 'todos',\n",
       " 'su']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These two objects will be used to change the morphology of words and replace stop words within a POS respectively.",
   "id": "c1321db54d86e694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:32:47.910017Z",
     "start_time": "2024-05-26T18:32:47.902655Z"
    }
   },
   "cell_type": "code",
   "source": "sentence_modifier = SentenceModifier(nlp_model, inflector, stop_word_dictionary, transformation_rate=0.5)",
   "id": "8ee1028fec5d0ee3",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using this sentence modifier we can start applying modifications to our texts",
   "id": "4bec8b3e050cfe4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Morphological changes",
   "id": "fb1f4acaf65383ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:36:45.210389Z",
     "start_time": "2024-05-26T18:36:45.187987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = nlp_model(texts[7])\n",
    "print(f'SENTENCE: {sentence}')\n",
    "words = sentence_modifier.sentence_words(sentence)\n",
    "tokens = [None] + list(sentence)\n",
    "initial_labels = [KEEP] * len(words)\n",
    "\n",
    "print('________ORIGINAL SENTENCE________')\n",
    "print(pd.DataFrame({'words': words, 'tokens': tokens, 'labels': initial_labels}))\n",
    "print()\n",
    "\n",
    "changed_words, changed_tokens, labels = sentence_modifier.transform_morphology(words, tokens, initial_labels)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'tokens': changed_tokens, 'labels': labels}))"
   ],
   "id": "33f9096404f992ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: Su apego a todos ellos fue creciendo con el tiempo\n",
      "________ORIGINAL SENTENCE________\n",
      "          words     tokens labels\n",
      "0   @@PADDING@@       None  $KEEP\n",
      "1            Su         Su  $KEEP\n",
      "2         apego      apego  $KEEP\n",
      "3             a          a  $KEEP\n",
      "4         todos      todos  $KEEP\n",
      "5         ellos      ellos  $KEEP\n",
      "6           fue        fue  $KEEP\n",
      "7     creciendo  creciendo  $KEEP\n",
      "8           con        con  $KEEP\n",
      "9            el         el  $KEEP\n",
      "10       tiempo     tiempo  $KEEP\n",
      "\n",
      "________MODIFIED SENTENCE________\n",
      "          words     tokens       labels\n",
      "0   @@PADDING@@       None        $KEEP\n",
      "1            Su         Su        $KEEP\n",
      "2         apego      apego        $KEEP\n",
      "3             a          a        $KEEP\n",
      "4         todos      todos        $KEEP\n",
      "5         ellos      ellos        $KEEP\n",
      "6           fue        fue        $KEEP\n",
      "7     creciendo  creciendo        $KEEP\n",
      "8           con        con        $KEEP\n",
      "9           los       None  $REPLACE_el\n",
      "10       tiempo     tiempo        $KEEP\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Replace a stop word",
   "id": "2a648a8946f457e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:20:09.821831Z",
     "start_time": "2024-05-26T16:20:09.793212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = nlp_model(texts[1])\n",
    "print(f'SENTENCE: {sentence}')\n",
    "words = sentence_modifier.sentence_words(sentence)\n",
    "tokens = [None] + list(sentence)\n",
    "initial_labels = [KEEP] * len(words)\n",
    "\n",
    "print('________ORIGINAL SENTENCE________')\n",
    "print(pd.DataFrame({'words': words, 'tokens': tokens, 'labels': initial_labels}))\n",
    "print()\n",
    "\n",
    "changed_words, changed_tokens, labels = sentence_modifier.transform_within_poss(words, tokens, initial_labels)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'tokens': changed_tokens, 'labels': labels}))"
   ],
   "id": "9dba4a46716e6144",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: La familia Dashwood llevaba largo tiempo afincada en Sussex\n",
      "________ORIGINAL SENTENCE________\n",
      "         words    tokens labels\n",
      "0  @@PADDING@@      None  $KEEP\n",
      "1           La        La  $KEEP\n",
      "2      familia   familia  $KEEP\n",
      "3     Dashwood  Dashwood  $KEEP\n",
      "4      llevaba   llevaba  $KEEP\n",
      "5        largo     largo  $KEEP\n",
      "6       tiempo    tiempo  $KEEP\n",
      "7     afincada  afincada  $KEEP\n",
      "8           en        en  $KEEP\n",
      "9       Sussex    Sussex  $KEEP\n",
      "\n",
      "________MODIFIED SENTENCE________\n",
      "         words    tokens       labels\n",
      "0  @@PADDING@@      None        $KEEP\n",
      "1           La        La        $KEEP\n",
      "2      familia   familia        $KEEP\n",
      "3     Dashwood  Dashwood        $KEEP\n",
      "4      llevaba   llevaba        $KEEP\n",
      "5        largo     largo        $KEEP\n",
      "6       tiempo    tiempo        $KEEP\n",
      "7     afincada  afincada        $KEEP\n",
      "8          con      None  $REPLACE_en\n",
      "9       Sussex    Sussex        $KEEP\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Elimination of stop words",
   "id": "18f4d404d4d56301"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:24:36.922748Z",
     "start_time": "2024-05-26T16:24:36.907462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = nlp_model(texts[1])\n",
    "print(f'SENTENCE: {sentence}')\n",
    "words = sentence_modifier.sentence_words(sentence)\n",
    "tokens = [None] + list(sentence)\n",
    "initial_labels = [KEEP] * len(words)\n",
    "\n",
    "print('________ORIGINAL SENTENCE________')\n",
    "print(pd.DataFrame({'words': words, 'tokens': tokens, 'labels': initial_labels}))\n",
    "print()\n",
    "\n",
    "changed_words, changed_tokens, labels = sentence_modifier.transform_elimination(words, tokens, initial_labels)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'tokens': changed_tokens, 'labels': labels}))"
   ],
   "id": "aa2a785b176cfb95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: La familia Dashwood llevaba largo tiempo afincada en Sussex\n",
      "________ORIGINAL SENTENCE________\n",
      "         words    tokens labels\n",
      "0  @@PADDING@@      None  $KEEP\n",
      "1           La        La  $KEEP\n",
      "2      familia   familia  $KEEP\n",
      "3     Dashwood  Dashwood  $KEEP\n",
      "4      llevaba   llevaba  $KEEP\n",
      "5        largo     largo  $KEEP\n",
      "6       tiempo    tiempo  $KEEP\n",
      "7     afincada  afincada  $KEEP\n",
      "8           en        en  $KEEP\n",
      "9       Sussex    Sussex  $KEEP\n",
      "\n",
      "________MODIFIED SENTENCE________\n",
      "         words    tokens      labels\n",
      "0  @@PADDING@@      None       $KEEP\n",
      "1           La        La       $KEEP\n",
      "2      familia   familia       $KEEP\n",
      "3     Dashwood  Dashwood       $KEEP\n",
      "4      llevaba   llevaba       $KEEP\n",
      "5        largo     largo       $KEEP\n",
      "6       tiempo    tiempo       $KEEP\n",
      "7     afincada  afincada  $APPEND_en\n",
      "8       Sussex    Sussex       $KEEP\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adding stop words",
   "id": "75412d13d0b9d573"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:26:43.614316Z",
     "start_time": "2024-05-26T16:26:43.604297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = nlp_model(texts[1])\n",
    "print(f'SENTENCE: {sentence}')\n",
    "words = sentence_modifier.sentence_words(sentence)\n",
    "tokens = [None] + list(sentence)\n",
    "initial_labels = [KEEP] * len(words)\n",
    "\n",
    "print('________ORIGINAL SENTENCE________')\n",
    "print(pd.DataFrame({'words': words, 'tokens': tokens, 'labels': initial_labels}))\n",
    "print()\n",
    "\n",
    "changed_words, changed_tokens, labels = sentence_modifier.transform_adding(words, tokens, initial_labels)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'tokens': changed_tokens, 'labels': labels}))"
   ],
   "id": "26c568da01373bd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: La familia Dashwood llevaba largo tiempo afincada en Sussex\n",
      "________ORIGINAL SENTENCE________\n",
      "         words    tokens labels\n",
      "0  @@PADDING@@      None  $KEEP\n",
      "1           La        La  $KEEP\n",
      "2      familia   familia  $KEEP\n",
      "3     Dashwood  Dashwood  $KEEP\n",
      "4      llevaba   llevaba  $KEEP\n",
      "5        largo     largo  $KEEP\n",
      "6       tiempo    tiempo  $KEEP\n",
      "7     afincada  afincada  $KEEP\n",
      "8           en        en  $KEEP\n",
      "9       Sussex    Sussex  $KEEP\n",
      "\n",
      "________MODIFIED SENTENCE________\n",
      "          words    tokens   labels\n",
      "0   @@PADDING@@      None    $KEEP\n",
      "1            La        La    $KEEP\n",
      "2       familia   familia    $KEEP\n",
      "3      Dashwood  Dashwood    $KEEP\n",
      "4       llevaba   llevaba    $KEEP\n",
      "5        estáis      None  $DELETE\n",
      "6         largo     largo    $KEEP\n",
      "7        tiempo    tiempo    $KEEP\n",
      "8      afincada  afincada    $KEEP\n",
      "9            en        en    $KEEP\n",
      "10       Sussex    Sussex    $KEEP\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Token fusion",
   "id": "74f8e65e25149dae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:28:41.924020Z",
     "start_time": "2024-05-26T16:28:41.903574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = nlp_model(texts[1])\n",
    "print(f'SENTENCE: {sentence}')\n",
    "words = sentence_modifier.sentence_words(sentence)\n",
    "tokens = [None] + list(sentence)\n",
    "initial_labels = [KEEP] * len(words)\n",
    "\n",
    "print('________ORIGINAL SENTENCE________')\n",
    "print(pd.DataFrame({'words': words, 'tokens': tokens, 'labels': initial_labels}))\n",
    "print()\n",
    "\n",
    "changed_words, changed_tokens, labels = sentence_modifier.transform_token_fusion(words, tokens, initial_labels)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'tokens': changed_tokens, 'labels': labels}))"
   ],
   "id": "cf8f09c5ab12b791",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: La familia Dashwood llevaba largo tiempo afincada en Sussex\n",
      "________ORIGINAL SENTENCE________\n",
      "         words    tokens labels\n",
      "0  @@PADDING@@      None  $KEEP\n",
      "1           La        La  $KEEP\n",
      "2      familia   familia  $KEEP\n",
      "3     Dashwood  Dashwood  $KEEP\n",
      "4      llevaba   llevaba  $KEEP\n",
      "5        largo     largo  $KEEP\n",
      "6       tiempo    tiempo  $KEEP\n",
      "7     afincada  afincada  $KEEP\n",
      "8           en        en  $KEEP\n",
      "9       Sussex    Sussex  $KEEP\n",
      "\n",
      "________MODIFIED SENTENCE________\n",
      "             words    tokens    labels\n",
      "0      @@PADDING@@      None     $KEEP\n",
      "1               La        La     $KEEP\n",
      "2          familia   familia     $KEEP\n",
      "3  Dashwoodllevaba      None  $SPLIT_8\n",
      "4            largo     largo     $KEEP\n",
      "5           tiempo    tiempo     $KEEP\n",
      "6         afincada  afincada     $KEEP\n",
      "7               en        en     $KEEP\n",
      "8           Sussex    Sussex     $KEEP\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Putting it all together",
   "id": "2e9662380e9595ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:42:41.176839Z",
     "start_time": "2024-05-26T18:42:41.168948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = nlp_model(texts[1])\n",
    "print(f'SENTENCE: {sentence}')\n",
    "\n",
    "changed_words, changed_tokens, labels = sentence_modifier.randomly_transform(sentence)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'tokens': changed_tokens, 'labels': labels}))"
   ],
   "id": "80f8c9bc6786c8e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: La familia Dashwood llevaba largo tiempo afincada en Sussex\n",
      "________MODIFIED SENTENCE________\n",
      "             words    tokens       labels\n",
      "0      @@PADDING@@      None   $APPEND_La\n",
      "1          familia   familia        $KEEP\n",
      "2  Dashwoodllevaba      None     $SPLIT_8\n",
      "3            largo     largo        $KEEP\n",
      "4           tiempo    tiempo        $KEEP\n",
      "5           siente      None      $DELETE\n",
      "6         afincada  afincada        $KEEP\n",
      "7               De      None  $REPLACE_en\n",
      "8           Sussex    Sussex        $KEEP\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Grammar Error Correction\n",
    "\n",
    "Now that we have our text with errors we can correct it using the labels"
   ],
   "id": "ebcdf92365875cec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:43:08.634112Z",
     "start_time": "2024-05-26T18:43:08.629389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gec_no_model = GrammarErrorCorrector(None, None)\n",
    "\n",
    "print('________MODIFIED SENTENCE________')\n",
    "print(pd.DataFrame({'words': changed_words, 'labels': labels}))\n",
    "\n",
    "corrected_words, corrected_labels = gec_no_model.correct_label_errors(changed_words, labels)\n",
    "\n",
    "print('________CORRECTED SENTENCE________')\n",
    "print(pd.DataFrame({'words': corrected_words, 'labels': corrected_labels}))"
   ],
   "id": "2c138338d34089b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________MODIFIED SENTENCE________\n",
      "             words       labels\n",
      "0      @@PADDING@@   $APPEND_La\n",
      "1          familia        $KEEP\n",
      "2  Dashwoodllevaba     $SPLIT_8\n",
      "3            largo        $KEEP\n",
      "4           tiempo        $KEEP\n",
      "5           siente      $DELETE\n",
      "6         afincada        $KEEP\n",
      "7               De  $REPLACE_en\n",
      "8           Sussex        $KEEP\n",
      "________CORRECTED SENTENCE________\n",
      "         words labels\n",
      "0  @@PADDING@@  $KEEP\n",
      "1           La  $KEEP\n",
      "2      familia  $KEEP\n",
      "3     Dashwood  $KEEP\n",
      "4      llevaba  $KEEP\n",
      "5        largo  $KEEP\n",
      "6       tiempo  $KEEP\n",
      "7     afincada  $KEEP\n",
      "8           en  $KEEP\n",
      "9       Sussex  $KEEP\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing the data for training\n",
    "\n",
    "Before we can use this data for training we have to tackle a particular problem. While our dataset is created based on word-wise tokenization BERT and similar models use word-piece tokenization. "
   ],
   "id": "d2717f6d9da98561"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:43:54.274976Z",
     "start_time": "2024-05-26T18:43:53.271073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_id = \"MMG/xlm-roberta-large-ner-spanish\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_tokens('@@PADDING@@')\n",
    "print(f'SENTENCE: {texts[1]}')\n",
    "print(f'SPACY TOKENS: {list(nlp_model.tokenizer(texts[1]))}')\n",
    "print(f'ROBERTA TOKENS: {tokenizer.tokenize(texts[1])}')"
   ],
   "id": "4b9e8c5b4d9e3e1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gustavo/Documents/mlt-project/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE: La familia Dashwood llevaba largo tiempo afincada en Sussex\n",
      "SPACY TOKENS: [La, familia, Dashwood, llevaba, largo, tiempo, afincada, en, Sussex]\n",
      "ROBERTA TOKENS: ['▁La', '▁familia', '▁Das', 'h', 'wood', '▁lleva', 'ba', '▁largo', '▁tiempo', '▁afin', 'cada', '▁en', '▁Sus', 'sex']\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Token-Label alignment\n",
    "\n",
    "This means that we need to align our dataset labels with the actual tokens expected by the model"
   ],
   "id": "f47254294efcafdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:45:08.025227Z",
     "start_time": "2024-05-26T18:45:08.012820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"modified_words\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "id": "9a3303a7b432caa7",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T18:45:10.371465Z",
     "start_time": "2024-05-26T18:45:10.366896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example = {\n",
    "    'modified_words': [changed_words],\n",
    "    'ner_tags': [labels]\n",
    "}\n",
    "\n",
    "aligned_data = tokenize_and_align_labels(examples=example)\n",
    "print(aligned_data)\n",
    "aligned_data = {k: v[0] for k, v in aligned_data.items()}\n",
    "aligned_data['token_text'] = tokenizer.convert_ids_to_tokens(aligned_data['input_ids'])\n",
    "print(pd.DataFrame(aligned_data))"
   ],
   "id": "87b8772bcdd5141c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[0, 250002, 8650, 1858, 127, 25876, 1229, 120550, 23321, 7493, 167264, 17770, 23315, 262, 26832, 13802, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, '$APPEND_La', '$KEEP', '$SPLIT_8', -100, -100, -100, -100, '$KEEP', '$KEEP', '$DELETE', '$KEEP', -100, '$REPLACE_en', '$KEEP', -100, -100]]}\n",
      "    input_ids  attention_mask       labels   token_text\n",
      "0           0               1         -100          <s>\n",
      "1      250002               1   $APPEND_La  @@PADDING@@\n",
      "2        8650               1        $KEEP     ▁familia\n",
      "3        1858               1     $SPLIT_8         ▁Das\n",
      "4         127               1         -100            h\n",
      "5       25876               1         -100         wood\n",
      "6        1229               1         -100          lle\n",
      "7      120550               1         -100         vaba\n",
      "8       23321               1        $KEEP       ▁largo\n",
      "9        7493               1        $KEEP      ▁tiempo\n",
      "10     167264               1      $DELETE      ▁siente\n",
      "11      17770               1        $KEEP        ▁afin\n",
      "12      23315               1         -100         cada\n",
      "13        262               1  $REPLACE_en          ▁De\n",
      "14      26832               1        $KEEP         ▁Sus\n",
      "15      13802               1         -100          sex\n",
      "16          2               1         -100         </s>\n"
     ]
    }
   ],
   "execution_count": 81
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
